{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Wellesley College Honors Theses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook created by Marisa Papagelis as part of the Wellesley Data Collective January 2021 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, We will scrape the [Wellesely College Honors Theses Repository](https://repository.wellesley.edu/collections/thesiscollection?display=grid) for Senior Theses titles, years, and departments using Selenium, BeautifulSoup, and Pandas. \n",
    "\n",
    "This product of this notebook results in a json file of our data which we hope is useful in Wellesley data focused projects. We also hope this code can be reused in the future to scrape the most recent Senior Honors Theses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install Selenium and import appropriate packages which we will use in this notebook. We will use Selenium's webdriver to navigate our Senior Theses pages, BeautifulSoup to scrape, pandas to create our dataset, and json to save and export our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.8/site-packages (3.141.0)\r\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.25.9)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigate to Honors Theses Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use chromedriver to open a chrome browser and navigate to the first theses page we want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='Downloads/chromedriver3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://repository.wellesley.edu/collections/thesiscollection?display=grid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use BeautifulSoup along with some helper functions to parse through the theses webpage. We inspected the page in our chrome browser to find the class names for the year, department, and title of each thesis on the page. We then used BeautifulSoup's .find function to pull the appropriate content from each thesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(driver.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThesisYear(content): \n",
    "    \"\"\"A helper function to determine the year of the thesis\"\"\"\n",
    "    post_el = content.find(\"div\", \n",
    "                           class_=\"d-inline-block solr-value mods-origininfo-type-displaydate-dateother-ms\")\n",
    "    if post_el: \n",
    "        return post_el.text\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThesisDepartment(content): \n",
    "    \"\"\"A helper function to determine the departmnet of the thesis\"\"\"\n",
    "    post_el = content.find(\"div\", \n",
    "                           class_=\"d-inline-block solr-value mods-name-corporate-department-namepart-ms\")\n",
    "    if post_el: \n",
    "        return post_el.text\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThesisTitle(content): \n",
    "    \"\"\"A helper function to determine the title of the thesis\"\"\"\n",
    "    post_el = content.find(\"div\", \n",
    "                           class_=\"d-inline-block solr-value fgs-label-s\")\n",
    "    if post_el: \n",
    "        return post_el.text\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the First Page of Theses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop through each thesis on the given page and collect the year, department, and title. We do this by finding the class containing all of the theses and looping through it. We append these data to a list which we will refer back to after all of the pages are scraped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_data = [] \n",
    "for thesis in soup.find_all(\"div\", class_=\"solr-fields islandora-inline-metadata col-xs-12 col-sm-8 col-md-9\"):\n",
    "    try:\n",
    "        thesis_year = getThesisYear(thesis)\n",
    "        thesis_department = getThesisDepartment(thesis)\n",
    "        thesis_title = getThesisTitle(thesis)\n",
    "        thesis_data.append((thesis_year, thesis_department, thesis_title))\n",
    "    except AttributeError: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Additional Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to scrape the rest of the pages, we need to use our driver to navigate to each page and use our helper functions to scrape the thesis year, department, and title. We append these data to our list to use at the very end of the tutorial. \n",
    "\n",
    "First, we create a list hold all of our future URLs. Since there are currently 34 pages of theses, and page 1 has a URL without a number, we will have 33 URLs to navigate. We create all 33 new URLs using a loop, and we append these URLs to a list for our scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = []\n",
    "page = 0\n",
    "for article in range(33):\n",
    "    page += 1\n",
    "    URL = \"https://repository.wellesley.edu/collections/thesiscollection?page=\" + str(page) + \"&display=grid\"\n",
    "    URLs.append(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we loop through our URLs and scrape the appropriate information from each Honors Theses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for URL in URLs: \n",
    "    for thesis in soup.find_all(\"div\", class_=\"solr-fields islandora-inline-metadata col-xs-12 col-sm-8 col-md-9\"):\n",
    "        try:\n",
    "            thesis_year = getThesisYear(thesis)\n",
    "            thesis_department = getThesisDepartment(thesis)\n",
    "            thesis_title = getThesisTitle(thesis)\n",
    "            thesis_data.append((thesis_year, thesis_department, thesis_title))\n",
    "        except AttributeError: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Data Frame for Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a data frame using the pandas package and save our data to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "theses_df = pd.DataFrame(thesis_data, columns=[\"Year\", \"Department\", \"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Department</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>Unilateral Friendship Outcomes and Preschool F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>Biological Sciences</td>\n",
       "      <td>Beyond Prosthetics: the First Steps Towards Id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>Filling Political Spaces: Iraqi, Humanitarian-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>English</td>\n",
       "      <td>True Fiction: Three Writers' Approaches to Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>East Asian Languages and Literatures</td>\n",
       "      <td>The Making of a Mountain: Mount Fuji, Miniatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2015</td>\n",
       "      <td>Cinema and Media Studies</td>\n",
       "      <td>Kino: CAMS Production Honors Thesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2015</td>\n",
       "      <td>American Studies</td>\n",
       "      <td>Finding Their Sphere: Feminist Communication i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2015</td>\n",
       "      <td>International Relations, Political Science</td>\n",
       "      <td>China's Soft Power in the Arab World through H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2015</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Privacy Implications of New York City's Stop-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2015</td>\n",
       "      <td>English</td>\n",
       "      <td>The Allincluding Language of Ulysses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year                                  Department  \\\n",
       "0    2015                                  Psychology   \n",
       "1    2015                         Biological Sciences   \n",
       "2    2015                           Political Science   \n",
       "3    2015                                     English   \n",
       "4    2015        East Asian Languages and Literatures   \n",
       "..    ...                                         ...   \n",
       "675  2015                    Cinema and Media Studies   \n",
       "676  2015                            American Studies   \n",
       "677  2015  International Relations, Political Science   \n",
       "678  2015                            Computer Science   \n",
       "679  2015                                     English   \n",
       "\n",
       "                                                 Title  \n",
       "0    Unilateral Friendship Outcomes and Preschool F...  \n",
       "1    Beyond Prosthetics: the First Steps Towards Id...  \n",
       "2    Filling Political Spaces: Iraqi, Humanitarian-...  \n",
       "3    True Fiction: Three Writers' Approaches to Fac...  \n",
       "4    The Making of a Mountain: Mount Fuji, Miniatur...  \n",
       "..                                                 ...  \n",
       "675                Kino: CAMS Production Honors Thesis  \n",
       "676  Finding Their Sphere: Feminist Communication i...  \n",
       "677  China's Soft Power in the Arab World through H...  \n",
       "678  Privacy Implications of New York City's Stop-a...  \n",
       "679               The Allincluding Language of Ulysses  \n",
       "\n",
       "[680 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theses_df #view data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data frame, we export it to a json file so it can be used in further exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(thesis_data, open('WellesleyHonorsTheses.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done scraping the Wellesley College Honors Theses! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
